{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e49e21-4b1f-4603-a619-84b9e1998f03",
   "metadata": {},
   "source": [
    "# 509 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32969aa-7653-4aab-a91f-52dc53dc26e5",
   "metadata": {},
   "source": [
    "This notebook connects to the NewAPI to return JSOn objects based on specific queries, loads specific elements from the object, then persists the data in a MySQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41799b8c-019d-4d02-914a-107c15e3c572",
   "metadata": {},
   "source": [
    "## Resolve dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156706dd-43a9-49ff-8fa3-f61f0dc9cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi-python in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-tf\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-tf\\lib\\site-packages (from newsapi-python) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-tf\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-tf\\lib\\site-packages (from requests<3.0.0->newsapi-python) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-tf\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-tf\\lib\\site-packages (from requests<3.0.0->newsapi-python) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "! pip install newsapi-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c57862-dbc2-4515-b62e-14adccbf6d2b",
   "metadata": {},
   "source": [
    "## Globally import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c1e3ef-8619-4237-88c3-e4a06edaf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql as mysql\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import re\n",
    "import regex as rex\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "#import mysql.connector\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Set pandas global options\n",
    "pd.options.display.max_rows = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5362756a-b723-45c8-8ddf-96c76c525b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-17\n",
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "today = dt.date.today()\n",
    "print(today)\n",
    "print(type(today))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8787f58-5e3f-4200-b947-3fc11d9b00e1",
   "metadata": {},
   "source": [
    "## Connect to NewsAPI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fae3237-1881-4b51-8ef3-89d519df07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['NewsAPIKey']\n",
    "\n",
    "# Init\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace829b-46ef-4364-98ca-e8bddf331a8a",
   "metadata": {},
   "source": [
    "## Pull article info from API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca0d3c-fdab-4394-9f01-0c58fac0b409",
   "metadata": {},
   "source": [
    "sources = newsapi.get_sources()\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1b41dd-e69a-40b7-baaa-ab45308d24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_api_urls(q=None,\n",
    "                  s=None,\n",
    "                  d_from='2023-05-01',\n",
    "                  d_to='2023-05-31',\n",
    "                  api_lst=[]):\n",
    "    '''Access API and pull content from resulting JSON object'''\n",
    "    all_articles = newsapi.get_everything(q=q,\n",
    "                                          sources=s,\n",
    "                                          from_param=d_from,\n",
    "                                          to=d_to,\n",
    "                                          language='en',\n",
    "                                          sort_by='relevancy',\n",
    "                                          page=1)\n",
    "\n",
    "    #print(type(all_articles))\n",
    "    #print(all_articles)\n",
    "    #print('Article list: ', all_articles['articles'])\n",
    "    #for article in all_articles['articles']:\n",
    "        #print('Source ID:', article['source']['id'])\n",
    "        #print('Source name:', article['source']['name'])\n",
    "        #print('Author:', article['author'])\n",
    "        #print('Title:', article['title'])\n",
    "        #print('URL:', article['url'])\n",
    "        #print('Publish date:', article['publishedAt'])\n",
    "        #print('Article text:', article['content'], '\\n')\n",
    "\n",
    "    # Create a list of tuples from the dictionary data\n",
    "    source_data01 = [(a['source']['name'],\n",
    "                      a['author'],\n",
    "                      a['title'],\n",
    "                      a['url'],\n",
    "                      a['publishedAt'],\n",
    "                      a['content'])\n",
    "                     for a in all_articles['articles']]\n",
    "\n",
    "    api_lst.extend(source_data01)\n",
    "    #print(api_lst)\n",
    "    return(len(api_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e798fa2-c6c3-403a-9447-45ce85b22b02",
   "metadata": {},
   "source": [
    "## Connect to API to access URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7d5cf-9cdf-48a6-859d-3ea5fd230015",
   "metadata": {},
   "source": [
    "### Set API filter parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a065004-db65-4d58-b5d1-51a2fd65bec9",
   "metadata": {},
   "source": [
    "A request grid was established to return specific combinations of sources ('left' and 'right', as determined by referencing Allsides (2022) and Ralph et al. (2018)); dates; and keywords (\"hot button\" general terms, as inspired by Liu et al. (2022)). The grid was necessary to maximize the returned JSON objects, as each request/page was limited to 100 URLs. As an example, a grid of 4 sources, over 4 days, using 6 complex query terms resulted in a 96-request grid, where each request returned between 0 and 100 objects. Since there were some articles that overlapped in terms of keywords, and some sources did not include a specific keyword on any given day, the actual number of URLs was significantly less than the potential maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a1330d-6e03-4e1f-b2c6-6393d2a89ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total API request grid: Sources x dates x keyword queries\n",
    "'''Left/Right source selection critera: Allsides, 2022; Ralph et al., 2018'''\n",
    "source_lst = ['cnn', 'the-washington-post', 'fox-news', 'breitbart-news']\n",
    "#source_lst = ['cnn', 'reuters', 'fox-news']\n",
    "#source_lst = ['cnn', 'newsweek', 'fox-news']\n",
    "#source_lst = ['newsweek']\n",
    "#source_lst = ['cnn', 'fox-news']\n",
    "#source_lst = ['breitbart-news']\n",
    "\n",
    "'''Dates needed to be sliced based on NewsAPI rate limit of 100 request/day'''\n",
    "date_lst = ['2023-06-16', '2023-06-15']\n",
    "#date_lst = ['2023-06-14', '2023-06-13', '2023-06-12']\n",
    "#date_lst = ['2023-06-11', '2023-06-10', '2023-06-09', '2023-06-08']\n",
    "#date_lst = ['2023-06-07', '2023-06-06', '2023-06-05', '2023-06-04']\n",
    "#date_lst = ['2023-06-03', '2023-06-02', '2023-06-01', '2023-05-31', '2023-05-30', '2023-05-29']\n",
    "#date_lst = ['2023-06-03', '2023-06-02']\n",
    "#date_lst = ['2023-06-01', '2023-05-31']\n",
    "#date_lst = ['2023-05-30', '2023-05-29']\n",
    "#date_lst = ['2023-05-17', '2023-05-16', '2023-05-15', '2023-05-14', '2023-05-13']\n",
    "#date_lst = ['2023-05-12', '2023-05-11', '2023-05-10', '2023-05-09']\n",
    "#date_lst = ['2023-05-08']\n",
    "#date_lst = ['2023-05-07', '2023-05-06', '2023-05-05']\n",
    "\n",
    "'''Keyword selection critera: Liu et al., 2022'''\n",
    "q_word_lst = ['gender OR male OR female OR transgender',\n",
    "              'security AND (social OR national)',\n",
    "              'justice OR surveillance',\n",
    "              'healthcare OR \"health care\"',\n",
    "              '''(political AND (bias OR party)) OR republican \n",
    "              OR democrat OR election''',\n",
    "              '''(policy AND (drug OR \"affirmative action\")) \n",
    "              OR regulate OR regulation''']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe7168-8e57-457b-b8e9-2effd17f2e4b",
   "metadata": {},
   "source": [
    "### Access API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5960daa3-3823-40f5-8869-1334e040e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: cnn; Date: 2023-06-16; Query: gender OR male OR female OR transgender; Count: 11\n",
      "Source: cnn; Date: 2023-06-16; Query: security AND (social OR national); Count: 23\n",
      "Source: cnn; Date: 2023-06-16; Query: justice OR surveillance; Count: 34\n",
      "Source: cnn; Date: 2023-06-16; Query: healthcare OR \"health care\"; Count: 38\n",
      "Source: cnn; Date: 2023-06-16; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 57\n",
      "Source: cnn; Date: 2023-06-16; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 60\n",
      "Source: cnn; Date: 2023-06-15; Query: gender OR male OR female OR transgender; Count: 67\n",
      "Source: cnn; Date: 2023-06-15; Query: security AND (social OR national); Count: 78\n",
      "Source: cnn; Date: 2023-06-15; Query: justice OR surveillance; Count: 100\n",
      "Source: cnn; Date: 2023-06-15; Query: healthcare OR \"health care\"; Count: 104\n",
      "Source: cnn; Date: 2023-06-15; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 129\n",
      "Source: cnn; Date: 2023-06-15; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 131\n",
      "Source: the-washington-post; Date: 2023-06-16; Query: gender OR male OR female OR transgender; Count: 133\n",
      "Source: the-washington-post; Date: 2023-06-16; Query: security AND (social OR national); Count: 141\n",
      "Source: the-washington-post; Date: 2023-06-16; Query: justice OR surveillance; Count: 148\n",
      "Source: the-washington-post; Date: 2023-06-16; Query: healthcare OR \"health care\"; Count: 151\n",
      "Source: the-washington-post; Date: 2023-06-16; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 163\n",
      "Source: the-washington-post; Date: 2023-06-16; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 163\n",
      "Source: the-washington-post; Date: 2023-06-15; Query: gender OR male OR female OR transgender; Count: 168\n",
      "Source: the-washington-post; Date: 2023-06-15; Query: security AND (social OR national); Count: 173\n",
      "Source: the-washington-post; Date: 2023-06-15; Query: justice OR surveillance; Count: 179\n",
      "Source: the-washington-post; Date: 2023-06-15; Query: healthcare OR \"health care\"; Count: 183\n",
      "Source: the-washington-post; Date: 2023-06-15; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 193\n",
      "Source: the-washington-post; Date: 2023-06-15; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 196\n",
      "Source: fox-news; Date: 2023-06-16; Query: gender OR male OR female OR transgender; Count: 234\n",
      "Source: fox-news; Date: 2023-06-16; Query: security AND (social OR national); Count: 248\n",
      "Source: fox-news; Date: 2023-06-16; Query: justice OR surveillance; Count: 280\n",
      "Source: fox-news; Date: 2023-06-16; Query: healthcare OR \"health care\"; Count: 288\n",
      "Source: fox-news; Date: 2023-06-16; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 335\n",
      "Source: fox-news; Date: 2023-06-16; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 338\n",
      "Source: fox-news; Date: 2023-06-15; Query: gender OR male OR female OR transgender; Count: 370\n",
      "Source: fox-news; Date: 2023-06-15; Query: security AND (social OR national); Count: 381\n",
      "Source: fox-news; Date: 2023-06-15; Query: justice OR surveillance; Count: 413\n",
      "Source: fox-news; Date: 2023-06-15; Query: healthcare OR \"health care\"; Count: 423\n",
      "Source: fox-news; Date: 2023-06-15; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 475\n",
      "Source: fox-news; Date: 2023-06-15; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 481\n",
      "Source: breitbart-news; Date: 2023-06-16; Query: gender OR male OR female OR transgender; Count: 493\n",
      "Source: breitbart-news; Date: 2023-06-16; Query: security AND (social OR national); Count: 500\n",
      "Source: breitbart-news; Date: 2023-06-16; Query: justice OR surveillance; Count: 511\n",
      "Source: breitbart-news; Date: 2023-06-16; Query: healthcare OR \"health care\"; Count: 513\n",
      "Source: breitbart-news; Date: 2023-06-16; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 538\n",
      "Source: breitbart-news; Date: 2023-06-16; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 541\n",
      "Source: breitbart-news; Date: 2023-06-15; Query: gender OR male OR female OR transgender; Count: 549\n",
      "Source: breitbart-news; Date: 2023-06-15; Query: security AND (social OR national); Count: 559\n",
      "Source: breitbart-news; Date: 2023-06-15; Query: justice OR surveillance; Count: 575\n",
      "Source: breitbart-news; Date: 2023-06-15; Query: healthcare OR \"health care\"; Count: 583\n",
      "Source: breitbart-news; Date: 2023-06-15; Query: (political AND (bias OR party)) OR republican \n",
      "              OR democrat OR election; Count: 614\n",
      "Source: breitbart-news; Date: 2023-06-15; Query: (policy AND (drug OR \"affirmative action\")) \n",
      "              OR regulate OR regulation; Count: 615\n"
     ]
    }
   ],
   "source": [
    "'''Run individual request for each source/data/keyword combo\n",
    "to maximize data scraped'''\n",
    "api_record_lst01 = []\n",
    "\n",
    "for s in source_lst:\n",
    "    #print(f'Source: {s}')\n",
    "    for d in date_lst:\n",
    "        #print(f'Date: {d}')\n",
    "        for q in q_word_lst:\n",
    "            #print(f'Query word: {q}')\n",
    "            time.sleep(5 + 11 * random.random())\n",
    "            lst_len = news_api_urls(q=q,\n",
    "                                    s=s,\n",
    "                                    d_from=d,\n",
    "                                    d_to=d,\n",
    "                                    api_lst=api_record_lst01)\n",
    "            print(f'Source: {s}; Date: {d}; Query: {q}; Count: {lst_len}')\n",
    "    \n",
    "    # Random wait to prevent access shutdown\n",
    "    time.sleep(10 + 13 * random.random())\n",
    "\n",
    "#print(api_record_lst01)\n",
    "#print(len(api_record_lst01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a04f8c-c5d3-4236-998a-a13bf09c0c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n"
     ]
    }
   ],
   "source": [
    "#print(api_record_lst01)\n",
    "print(len(api_record_lst01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f82433d-b1a9-4c22-b3b1-ac3c8208e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n"
     ]
    }
   ],
   "source": [
    "# Convert result list to set to eliminate duplicates\n",
    "api_record_set01 = set(api_record_lst01)\n",
    "#print(api_record_set01)\n",
    "api_record_lst02 = list(api_record_set01)\n",
    "#print(api_record_lst02)\n",
    "print(len(api_record_lst02))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0feec-4930-4d28-a6c2-d83288b781b7",
   "metadata": {},
   "source": [
    "## Initiate MySQL connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1e9561-e376-4262-aa6f-c59d45124989",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set local environment variables to hide user name & password citation:\n",
    "https://www.geeksforgeeks.org/how-to-hide-sensitive-credentials-using-python/\n",
    "'''\n",
    "user_name = os.environ['MySQLUSRAC']\n",
    "user_pass = os.environ['MySQLPWDAC']\n",
    "\n",
    "# Instantiate connection\n",
    "db_conn = mysql.connect(host='localhost',\n",
    "                        port=int(3306),\n",
    "                        user=user_name,\n",
    "                        passwd=user_pass,\n",
    "                        db='509_final_proj')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = db_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e753d762-a5ea-455a-8db6-b329eed96d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acarr\\AppData\\Local\\Temp\\ipykernel_2084\\4193860975.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  tbl_names = pd.read_sql('SHOW TABLES', db_conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_509_final_proj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nar_temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_articles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tables_in_509_final_proj\n",
       "0                 nar_temp\n",
       "1            news_articles"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "tbl_names = pd.read_sql('SHOW TABLES', db_conn)\n",
    "\n",
    "display(tbl_names)\n",
    "print(type(tbl_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd8db1-f81b-4b75-adbf-546c19cfab8b",
   "metadata": {},
   "source": [
    "### Establish logging policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f9b045-77c7-46b9-98ed-cb15b224bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Logging citations (see additional code in following code blocks:\n",
    "OpenAI. (2021). ChatGPT [Computer software]. https://openai.com/;\n",
    "https://docs.python.org/3/howto/logging.html#logging-basic-example;\n",
    "https://docs.python.org/3/howto/logging.html#logging-to-a-file;\n",
    "https://docs.python.org/3/howto\n",
    "/logging-cookbook.html#using-a-rotating-log-file-handler;\n",
    "https://docs.python.org/3/howto\n",
    "/logging-cookbook.html#using-a-timed-rotating-file-handler\n",
    "'''\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename='pymysql.log',\n",
    "                    filemode='a',\n",
    "                    format='''>>>>>>>>>>>>>><<<<<<<<<<<<<<\\n%(asctime)s - \n",
    "                    %(levelname)s - %(message)s''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5204295-2b32-45bf-b851-45f40fc5fdcf",
   "metadata": {},
   "source": [
    "### Update individual tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e51a9b-96b9-4e0d-ba5f-ef6acc5b60ef",
   "metadata": {},
   "source": [
    "#### Update `news_articles` table from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dead612-d53c-4ea6-b574-1248c09b21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_tbl_name = 'nar_temp'\n",
    "nwa_tbl_name = 'news_articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f4422f-123d-4d05-bcc8-7e41cfe08d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using cursor and loading into temp file:\n",
    "OpenAI. (2021). ChatGPT [Computer software]. https://openai.com/;\n",
    "https://pynative.com/python-mysql-insert-data-into-database-table/\n",
    "'''\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Wipe temp table\n",
    "try:\n",
    "    nat_dlt_tble_stmnt = f\"\"\"DELETE FROM {nat_tbl_name}\"\"\"\n",
    "    cursor.execute(nat_dlt_tble_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nat_dlt_tble_stmnt}\\n\\n\n",
    "    Records scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nat_dlt_tble_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n\n",
    "    >>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load data from CSV file into a temporary table\n",
    "try:\n",
    "    nat_csv_load_stmnt = f\"\"\"\n",
    "    INSERT INTO {nat_tbl_name}\n",
    "    (\n",
    "    source_name,\n",
    "    author,\n",
    "    title,\n",
    "    url,\n",
    "    publish_date,\n",
    "    content\n",
    "    )\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query with multiple values\n",
    "    cursor.executemany(nat_csv_load_stmnt, api_record_lst02)\n",
    "    #cursor.execute(nat_csv_load_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nat_csv_load_stmnt}\\n\\n\n",
    "    Records scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nat_csv_load_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n\n",
    "    >>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Insert new records into main table\n",
    "try:\n",
    "    nwa_load_stmnt = f\"\"\"\n",
    "    INSERT INTO {nwa_tbl_name}\n",
    "    (\n",
    "    source_name,\n",
    "    author,\n",
    "    title,\n",
    "    url,\n",
    "    publish_date,\n",
    "    content\n",
    "    )\n",
    "    SELECT\n",
    "        tp.source_name,\n",
    "        tp.author,\n",
    "        tp.title,\n",
    "        tp.url,\n",
    "        tp.publish_date,\n",
    "        tp.content\n",
    "    FROM {nat_tbl_name} AS tp\n",
    "    LEFT JOIN {nwa_tbl_name} AS mn\n",
    "    ON tp.title = mn.title\n",
    "    AND CAST(LEFT(tp.publish_date,10) AS DATE)=CAST(LEFT(mn.publish_date,10) AS DATE)\n",
    "    AND tp.author = mn.author\n",
    "    \"\"\"\n",
    "    cursor.execute(nwa_load_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nwa_load_stmnt}\\n\\n\n",
    "    Records scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nwa_load_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n\n",
    "    >>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Wipe temp table\n",
    "try:\n",
    "    cursor.execute(nat_dlt_tble_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nat_dlt_tble_stmnt}\\n\\n\n",
    "    Records scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nat_dlt_tble_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n\n",
    "    >>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699729c-2960-4519-b287-9a6f315a7e35",
   "metadata": {},
   "source": [
    "### Commit changes and close cursor and connection instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9228f3-083f-4fc1-850d-fc5e4bde40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes to the database\n",
    "db_conn.commit()\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cursor.close()\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc34a8d-dce8-4576-97af-a94ee25b61c6",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f8d5e-67d7-40e8-9f37-cfab6a34c3c8",
   "metadata": {},
   "source": [
    "* AllSides. (2022, March 15). *AllSides Media Bias Chart version 6: Updated ratings for NPR, Newsmax, and more*. https://www.allsides.com/blog/new-allsides-media-bias-chart-version-6-updated-ratings-nprnewsmax-and-more \\\n",
    "* Liu, R., Jia, C., Wei, J., Xu, G., & Vosoughi, S. (2022). Quantifying and alleviating political bias in language models. Artificial Intelligence, 304. https://doi.org/10.1016/j.artint.2021.103654 \\\n",
    "* Ralph, P., & Relman, E. (2018, September 2). These are the most and least biased news outlets in the US, according to Americans. Business Insider. https://www.businessinsider.com/most-biased-news-outlets-in-america-cnn-fox-nytimes-2018-8?op=1#and-heres-how-republicans-ranked-them-from-fox-news-to-cnn-20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
